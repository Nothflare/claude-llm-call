# LLM Call Configuration

# API Key (required)
API_KEY = "sk-or-v1-your-key-here"

# API Endpoint
ENDPOINT = "https://openrouter.ai/api/v1/chat/completions"

# Models
MODELS = {
    "gpt": "gpt-5.1-high",
    "gemini": "gemini-3-pro-preview",
    "grok": "grok-4.1-fast",
    "qwen": "qwen3-max",
}

# Display names
MODEL_NAMES = {
    "gpt": "GPT-5.1",
    "gemini": "Gemini-3-Pro",
    "grok": "Grok-4.1-Fast",
    "qwen": "Qwen3-Max",
}

# Request settings
MAX_TOKENS = 4096
TEMPERATURE = 0.7
TIMEOUT = 600  # seconds

# Parallel execution
MAX_WORKERS = 4  # Max concurrent API calls

# Debug output
DEBUG_OUTPUT = True  # Set to False to disable [llm-call] progress messages

# Session storage
SESSION_DIR = "/tmp/llm-call-sessions"

